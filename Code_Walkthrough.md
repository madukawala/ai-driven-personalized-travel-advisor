# Code Walkthrough: AI-Driven Personalized Travel Advisor

## Duration: 20 Minutes

---

## Part 1: Project Overview & Architecture (3 minutes)

### Technology Stack

**Backend:**
- FastAPI (Python) - Async REST API framework
- SQLAlchemy - ORM with async support
- SQLite - Development database
- LangGraph - AI workflow orchestration
- FAISS - Vector store for RAG
- Ollama - Local LLM (llama2)
- Sentence Transformers - Text embeddings

**Frontend:**
- React 18 - UI framework
- Vite - Build tool
- Tailwind CSS - Styling
- React Router - Navigation
- TanStack Query - Data fetching
- Recharts - Data visualization

### Project Structure

```
ai-driven-personalized-travel-advisor/
â”œâ”€â”€ backend/                    # FastAPI Backend
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ agents/            # LangGraph workflow
â”‚   â”‚   â”œâ”€â”€ api/               # REST & GraphQL endpoints
â”‚   â”‚   â”œâ”€â”€ database/          # Database configuration
â”‚   â”‚   â”œâ”€â”€ models/            # SQLAlchemy ORM models
â”‚   â”‚   â”œâ”€â”€ rag/               # RAG system components
â”‚   â”‚   â”œâ”€â”€ schemas/           # Pydantic validation schemas
â”‚   â”‚   â”œâ”€â”€ services/          # AI agents
â”‚   â”‚   â””â”€â”€ utils/             # Configuration utilities
â”‚   â””â”€â”€ tests/                 # Test suite
â”œâ”€â”€ frontend/                   # React Frontend
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ components/        # Reusable UI components
â”‚       â”œâ”€â”€ pages/             # Page components
â”‚       â””â”€â”€ services/          # API integration
â”œâ”€â”€ data/                      # Knowledge base storage
â”œâ”€â”€ scripts/                   # Utility scripts
â””â”€â”€ docs/                      # Documentation
```

### High-Level Architecture

The application implements a multi-agent AI system with RAG capabilities:

1. **User Interface Layer** - React frontend for user interaction
2. **API Layer** - FastAPI REST endpoints
3. **Orchestration Layer** - LangGraph workflow engine
4. **Agent Layer** - Four specialized AI agents
5. **Data Layer** - SQLite database + FAISS vector store
6. **Integration Layer** - External APIs (weather, events, currency)
7. **AI Layer** - Ollama LLM for text generation

---

## Part 2: Backend Core Components (5 minutes)

### Application Entry Point: `backend/app/main.py`

```python
# FastAPI application initialization
app = FastAPI(
    title="AI Travel Advisor API",
    description="AI-powered travel planning with RAG and multi-agent workflow",
    version="1.0.0"
)

# CORS configuration for frontend communication
app.add_middleware(
    CORSMiddleware,
    allow_origins=settings.ALLOWED_ORIGINS,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Mount routers
app.include_router(router, prefix="/api")
app.include_router(graphql_router, prefix="/graphql")
```

**Key Features:**
- Async FastAPI application
- CORS middleware for cross-origin requests
- REST API routes under `/api`
- GraphQL endpoint at `/graphql`
- Automatic OpenAPI documentation at `/docs`

### Database Models: `backend/app/models/`

**User Model** (`user.py`):
```python
class User(Base):
    __tablename__ = "users"

    id = Column(Integer, primary_key=True)
    username = Column(String, unique=True, nullable=False)
    email = Column(String, unique=True, nullable=False)
    hashed_password = Column(String, nullable=False)

    # Relationships
    trips = relationship("Trip", back_populates="user")
    conversations = relationship("Conversation", back_populates="user")
```

**Trip Model** (`trip.py`):
```python
class Trip(Base):
    __tablename__ = "trips"

    id = Column(Integer, primary_key=True)
    user_id = Column(Integer, ForeignKey("users.id"))
    destination = Column(String, nullable=False)
    start_date = Column(DateTime, nullable=False)
    end_date = Column(DateTime, nullable=False)
    budget = Column(Float, nullable=False)
    interests = Column(JSON)  # ["food", "culture", "nature"]
    constraints = Column(JSON)  # Dietary restrictions, mobility needs
    itinerary_json = Column(JSON)  # Generated itinerary
    risk_analysis = Column(JSON)  # Risk scores and analysis
    quality_score = Column(Integer)  # 0-100 trip quality score
    status = Column(String, default="planning")
```

**Conversation & Message Models** (`conversation.py`):
```python
class Conversation(Base):
    __tablename__ = "conversations"

    id = Column(Integer, primary_key=True)
    user_id = Column(Integer, ForeignKey("users.id"))
    title = Column(String)
    messages = relationship("Message", back_populates="conversation")

class Message(Base):
    __tablename__ = "messages"

    id = Column(Integer, primary_key=True)
    conversation_id = Column(Integer, ForeignKey("conversations.id"))
    role = Column(String)  # "user" or "assistant"
    content = Column(Text, nullable=False)
    created_at = Column(DateTime, default=datetime.utcnow)
```

**Database Design:**
- Relational model with proper foreign keys
- JSON columns for flexible data structures
- Relationships for easy data access
- Timestamps for audit trails

---

## Part 3: RAG System Implementation (4 minutes)

### RAG Architecture Overview

The RAG (Retrieval-Augmented Generation) system consists of three components:

1. **Embedding Service** - Converts text to vector embeddings
2. **Vector Store** - FAISS-based similarity search
3. **Knowledge Agent** - Orchestrates retrieval and ranking

### Embedding Service: `backend/app/rag/embeddings.py`

```python
class EmbeddingService:
    def __init__(self):
        self.model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')

    def generate_embedding(self, text: str) -> List[float]:
        """Generate embedding for single text"""
        embedding = self.model.encode(text, convert_to_tensor=False)
        return embedding.tolist()

    def generate_embeddings(self, texts: List[str]) -> List[List[float]]:
        """Generate embeddings for multiple texts (batched)"""
        embeddings = self.model.encode(texts, convert_to_tensor=False)
        return embeddings.tolist()
```

**Embedding Model:**
- Uses `all-MiniLM-L6-v2` (384-dimensional vectors)
- Fast inference (~50ms per text)
- Good balance of quality and speed
- Suitable for semantic similarity search

### Vector Store: `backend/app/rag/vector_store.py`

```python
class VectorStore:
    def __init__(self):
        self.embedding_service = EmbeddingService()
        self.index = None  # FAISS index
        self.documents = []  # Document metadata
        self.dimension = 384  # Embedding dimension

    def add_documents(self, texts: List[str], metadatas: List[Dict]):
        """Add documents to vector store"""
        # Generate embeddings
        embeddings = self.embedding_service.generate_embeddings(texts)
        embeddings_array = np.array(embeddings).astype('float32')

        # Create or update FAISS index
        if self.index is None:
            self.index = faiss.IndexFlatL2(self.dimension)

        # Add to index
        self.index.add(embeddings_array)

        # Store metadata
        for text, metadata in zip(texts, metadatas):
            self.documents.append({
                "text": text,
                "metadata": metadata
            })

    def search(self, query: str, k: int = 5) -> List[Dict]:
        """Search for similar documents"""
        if self.index is None or self.index.ntotal == 0:
            return []

        # Generate query embedding
        query_embedding = self.embedding_service.generate_embedding(query)
        query_array = np.array([query_embedding]).astype('float32')

        # Search FAISS index
        distances, indices = self.index.search(query_array, k)

        # Return results with scores
        results = []
        for i, idx in enumerate(indices[0]):
            if idx < len(self.documents):
                results.append({
                    "text": self.documents[idx]["text"],
                    "metadata": self.documents[idx]["metadata"],
                    "score": float(1 / (1 + distances[0][i]))  # Convert distance to similarity
                })

        return results
```

**FAISS Implementation:**
- `IndexFlatL2` - Exact L2 distance search
- Stores document text and metadata separately
- Converts L2 distances to similarity scores
- Supports batch operations for efficiency

### Knowledge Population: `scripts/populate_knowledge_base.py`

```python
SAMPLE_TRAVEL_DATA = [
    {
        "text": "Tokyo's Tsukiji Market - best visited 5-6 AM for fresh seafood...",
        "source_name": "Nomadic Matt",
        "destination": "Tokyo",
        "categories": ["food", "culture"],
        "source_url": "https://nomadicmatt.com/..."
    },
    # 12+ curated travel documents
]

# Populate vector store
vector_store = VectorStore()
texts = [doc["text"] for doc in SAMPLE_TRAVEL_DATA]
metadatas = [{k: v for k, v in doc.items() if k != "text"}
             for doc in SAMPLE_TRAVEL_DATA]

vector_store.add_documents(texts, metadatas)
vector_store.save("backend/data/faiss_index")
```

**Knowledge Sources:**
- Lonely Planet - Museum tips, practical advice
- Nomadic Matt - Food markets, budget tips
- TripAdvisor - Attraction guides
- Reddit Travel - Local experiences

---

## Part 4: AI Agents & Services (4 minutes)

### Agent Architecture

Four specialized agents work in sequence:

1. **Data Agent** - Fetches real-time data from external APIs
2. **Risk Agent** - Analyzes risks (budget, weather, crowding)
3. **Knowledge Agent** - Retrieves relevant travel knowledge
4. **Strategy Agent** - Generates final itinerary using LLM

### Data Agent: `backend/app/services/data_agent.py`

```python
class DataAgent:
    async def fetch_weather_data(self, location: str, start_date: datetime,
                                  end_date: datetime) -> Dict:
        """Fetch weather forecast from OpenWeatherMap API"""
        if not self.openweather_api_key:
            return self._generate_mock_weather(location, start_date, end_date)

        # Get coordinates
        geo_url = "http://api.openweathermap.org/geo/1.0/direct"
        geo_response = await client.get(geo_url, params={...})
        lat, lon = geo_data["lat"], geo_data["lon"]

        # Fetch 5-day forecast
        weather_url = "http://api.openweathermap.org/data/2.5/forecast"
        weather_response = await client.get(weather_url, params={...})

        return self._process_weather_data(weather_data, start_date, end_date)

    async def fetch_local_events(self, location: str, start_date: datetime,
                                  end_date: datetime) -> List[Dict]:
        """Fetch local events from Eventbrite API"""
        # Similar pattern - API call or mock data

    async def fetch_exchange_rate(self, from_currency: str,
                                   to_currency: str) -> Dict:
        """Fetch currency exchange rates"""
        # ExchangeRate API integration
```

**Data Sources:**
- OpenWeatherMap - Weather forecasts (5-day)
- Eventbrite - Local events and activities
- ExchangeRate API - Currency conversion
- Mock data fallback when no API keys

### Risk Agent: `backend/app/services/risk_agent.py`

```python
class RiskAgent:
    def analyze_budget_risk(self, budget: float, destination: str,
                            duration_days: int, interests: List[str],
                            exchange_rate: float) -> Dict:
        """Analyze budget adequacy and overrun risk"""
        # Base costs per day by destination tier
        destination_tier = self._classify_destination(destination)
        base_cost = {
            "budget": 50,
            "mid-range": 150,
            "luxury": 300
        }[destination_tier]

        # Interest-based cost multipliers
        interest_costs = {
            "food": 30, "culture": 20, "shopping": 50,
            "nightlife": 40, "adventure": 60
        }
        additional_cost = sum(interest_costs.get(i, 10) for i in interests)

        # Calculate estimated cost
        estimated_cost = (base_cost + additional_cost) * duration_days * exchange_rate

        # Risk assessment
        budget_ratio = estimated_cost / budget
        if budget_ratio > 1.5:
            risk = "high"
        elif budget_ratio > 1.2:
            risk = "medium"
        else:
            risk = "low"

        return {
            "estimated_cost": estimated_cost,
            "budget_ratio": budget_ratio,
            "overrun_risk": risk,
            "recommendations": self._generate_budget_recommendations(...)
        }

    def analyze_weather_risk(self, weather_data: Dict) -> Dict:
        """Analyze weather-related risks"""
        forecast = weather_data.get("forecast", [])
        rainy_days = sum(1 for day in forecast
                        if day.get("precipitation_chance", 0) > 60)

        # Risk scoring
        rain_percentage = (rainy_days / len(forecast)) * 100
        risk_level = "high" if rain_percentage > 40 else \
                     "medium" if rain_percentage > 20 else "low"

        return {
            "risk_level": risk_level,
            "rainy_days": rainy_days,
            "total_days": len(forecast),
            "rain_percentage": rain_percentage
        }

    def calculate_trip_quality_score(self, budget_risk: Dict,
                                      weather_risk: Dict,
                                      crowding_risk: Dict) -> Dict:
        """Calculate overall trip quality score (0-100)"""
        scores = {
            "budget": 100 - (budget_risk["budget_ratio"] - 1) * 50,
            "weather": 100 - weather_risk["rain_percentage"],
            "crowding": 100 if crowding_risk["risk_level"] == "low" else 60
        }

        overall_score = sum(scores.values()) / len(scores)

        return {
            "overall_score": int(overall_score),
            "component_scores": scores,
            "comfort_level": "high" if overall_score > 75 else "medium"
        }
```

**Risk Analysis Features:**
- Budget overrun prediction with recommendations
- Weather risk scoring (rain days, temperature extremes)
- Crowding analysis (events, holidays, peak seasons)
- Quality scoring (0-100 scale)

### Knowledge Agent: `backend/app/services/knowledge_agent.py`

```python
class KnowledgeAgent:
    def __init__(self):
        self.vector_store = VectorStore()
        self.vector_store.load("backend/data/faiss_index")

    async def retrieve_knowledge(self, query: str, location: str,
                                 user_interests: List[str],
                                 top_k: int = 5) -> List[Dict]:
        """Retrieve relevant travel knowledge using RAG"""
        # Enhance query with location and interests
        enhanced_query = f"{location} {query} {' '.join(user_interests)}"

        # Vector similarity search
        results = self.vector_store.search(enhanced_query, k=top_k * 2)

        # Filter by location relevance
        filtered_results = []
        for result in results:
            metadata = result.get("metadata", {})
            if location.lower() in str(metadata.get("locations", [])).lower():
                filtered_results.append(result)

        # Rank by relevance score and user interests
        ranked_results = self._rank_by_interests(
            filtered_results, user_interests
        )

        return ranked_results[:top_k]

    def _rank_by_interests(self, results: List[Dict],
                           interests: List[str]) -> List[Dict]:
        """Re-rank results based on user interests"""
        for result in results:
            categories = result.get("metadata", {}).get("categories", [])
            interest_match = sum(1 for cat in categories if cat in interests)
            result["interest_score"] = interest_match
            result["final_score"] = result["score"] * (1 + interest_match * 0.2)

        return sorted(results, key=lambda x: x["final_score"], reverse=True)
```

**RAG Features:**
- Query enhancement with location and interests
- Vector similarity search via FAISS
- Location-based filtering
- Interest-based re-ranking
- Relevance scoring

### Strategy Agent: `backend/app/services/strategy_agent.py`

```python
class StrategyAgent:
    def __init__(self):
        self.ollama_client = OllamaClient()

    async def generate_itinerary(self, destination: str, start_date: datetime,
                                 end_date: datetime, budget: float,
                                 interests: List[str], constraints: Dict,
                                 weather_data: Dict, knowledge_snippets: List[Dict],
                                 events: List[Dict], risk_analysis: Dict) -> Dict:
        """Generate comprehensive travel itinerary using LLM"""
        # Build comprehensive prompt
        prompt = self._build_itinerary_prompt(
            destination, start_date, end_date, budget, interests,
            constraints, weather_data, knowledge_snippets, events
        )

        # Generate itinerary using Ollama
        response = await self.ollama_client.generate(
            prompt,
            max_tokens=2000,
            temperature=0.7
        )

        # Parse and structure itinerary
        itinerary = self._parse_itinerary_response(response)

        # Add metadata
        itinerary["summary"] = {
            "destination": destination,
            "duration_days": (end_date - start_date).days,
            "total_estimated_cost": risk_analysis["budget_risk"]["estimated_cost"],
            "quality_score": risk_analysis["quality_score"]["overall_score"]
        }

        return itinerary

    def _build_itinerary_prompt(self, ...) -> str:
        """Build comprehensive prompt with all context"""
        prompt = f"""
        Create a detailed {duration_days}-day travel itinerary for {destination}.

        Trip Details:
        - Dates: {start_date.strftime('%Y-%m-%d')} to {end_date.strftime('%Y-%m-%d')}
        - Budget: ${budget}
        - Interests: {', '.join(interests)}
        - Constraints: {json.dumps(constraints)}

        Weather Forecast:
        {self._format_weather(weather_data)}

        Local Expert Tips:
        {self._format_knowledge(knowledge_snippets)}

        Local Events:
        {self._format_events(events)}

        Generate a day-by-day itinerary with:
        - Morning, afternoon, evening activities
        - Estimated costs per activity
        - Transportation recommendations
        - Dining suggestions
        - Weather-appropriate activities
        """
        return prompt
```

**Itinerary Generation:**
- Comprehensive prompt engineering
- Integration of all data sources
- LLM-based generation (Ollama)
- Structured output parsing
- Cost and quality metadata

---

## Part 5: LangGraph Workflow (3 minutes)

### Workflow Architecture: `backend/app/agents/langgraph_workflow.py`

```python
class TripPlanningWorkflow:
    def __init__(self):
        self.data_agent = DataAgent()
        self.risk_agent = RiskAgent()
        self.knowledge_agent = KnowledgeAgent()
        self.strategy_agent = StrategyAgent()
        self.graph = self._build_graph()

    def _build_graph(self):
        """Build LangGraph workflow"""
        if not LANGGRAPH_AVAILABLE:
            return None  # Fallback to sequential

        workflow = StateGraph(TripPlanningState)

        # Add nodes
        workflow.add_node("fetch_data", self._fetch_data_node)
        workflow.add_node("analyze_risks", self._analyze_risks_node)
        workflow.add_node("retrieve_knowledge", self._retrieve_knowledge_node)
        workflow.add_node("check_major_issues", self._check_major_issues_node)
        workflow.add_node("generate_itinerary", self._generate_itinerary_node)
        workflow.add_node("optimize_itinerary", self._optimize_itinerary_node)
        workflow.add_node("finalize", self._finalize_node)

        # Set entry point
        workflow.set_entry_point("fetch_data")

        # Add edges (flow)
        workflow.add_edge("fetch_data", "analyze_risks")
        workflow.add_edge("analyze_risks", "retrieve_knowledge")
        workflow.add_edge("retrieve_knowledge", "check_major_issues")

        # Conditional edge for human-in-the-loop
        workflow.add_conditional_edges(
            "check_major_issues",
            self._should_request_approval,
            {
                "generate_itinerary": "generate_itinerary",
                "end": END
            }
        )

        workflow.add_edge("generate_itinerary", "optimize_itinerary")
        workflow.add_edge("optimize_itinerary", "finalize")
        workflow.add_edge("finalize", END)

        return workflow.compile()
```

**Workflow Steps:**

1. **fetch_data_node** - Calls Data Agent to fetch weather, events, currency
2. **analyze_risks_node** - Calls Risk Agent to analyze all risks
3. **retrieve_knowledge_node** - Calls Knowledge Agent for RAG retrieval
4. **check_major_issues_node** - Evaluates if human approval needed
5. **generate_itinerary_node** - Calls Strategy Agent to create itinerary
6. **optimize_itinerary_node** - Applies weather and budget optimizations
7. **finalize_node** - Generates summary and quality score

**State Management:**

```python
class TripPlanningState(TypedDict):
    # Input
    destination: str
    start_date: str
    end_date: str
    budget: float
    interests: List[str]
    constraints: Dict[str, Any]

    # Collected data
    weather_data: Dict[str, Any]
    events_data: List[Dict[str, Any]]
    exchange_rate: Dict[str, Any]

    # Analysis
    risk_analysis: Dict[str, Any]
    knowledge_snippets: List[Dict[str, Any]]

    # Output
    itinerary: Dict[str, Any]

    # Workflow control
    requires_approval: bool
    approval_message: str
    current_step: str
```

**Human-in-the-Loop:**

```python
def _check_major_issues_node(self, state: TripPlanningState):
    """Check for issues requiring user approval"""
    requires_approval = False
    approval_message = ""

    # Check budget overrun
    budget_risk = state["risk_analysis"].get("budget_risk", {})
    if budget_risk.get("overrun_risk") == "high":
        requires_approval = True
        approval_message += f"âš ï¸ Budget Alert: Estimated costs {budget_risk['overrun_percentage']}% over budget. "

    # Check weather risks
    weather_risk = state["risk_analysis"].get("weather_risk", {})
    if weather_risk.get("risk_level") == "high":
        approval_message += f"ðŸŒ§ï¸ Weather Alert: {weather_risk['rainy_days']} rainy days expected. "

    state["requires_approval"] = requires_approval
    state["approval_message"] = approval_message
    return state
```

**Fallback Mechanism:**

```python
async def run(self, initial_state: Dict[str, Any]) -> Dict[str, Any]:
    """Run workflow with fallback"""
    if self.graph is not None and LANGGRAPH_AVAILABLE:
        # Use LangGraph
        result = await self.graph.ainvoke(state)
    else:
        # Fallback to sequential execution
        state = await self._fetch_data_node(state)
        state = await self._analyze_risks_node(state)
        state = await self._retrieve_knowledge_node(state)
        state = await self._check_major_issues_node(state)
        state = await self._generate_itinerary_node(state)
        state = await self._optimize_itinerary_node(state)
        state = await self._finalize_node(state)
        result = state

    return result
```

---

## Part 6: API Endpoints & Integration (3 minutes)

### REST API: `backend/app/api/routes.py`

**Trip Creation Endpoint:**

```python
@router.post("/trips", status_code=status.HTTP_201_CREATED)
async def create_trip(trip_data: TripCreate, user_id: int = 1,
                     db: AsyncSession = Depends(get_db)):
    """Create new trip and generate itinerary"""
    # Initialize workflow
    workflow = TripPlanningWorkflow()

    # Prepare state
    initial_state = {
        "destination": trip_data.destination,
        "start_date": trip_data.start_date.isoformat(),
        "end_date": trip_data.end_date.isoformat(),
        "budget": trip_data.budget,
        "interests": trip_data.interests,
        "constraints": trip_data.constraints,
        "user_id": user_id
    }

    # Run workflow (executes all agents)
    result = await workflow.run(initial_state)

    # Save to database
    trip = Trip(
        user_id=user_id,
        destination=trip_data.destination,
        start_date=trip_data.start_date,
        end_date=trip_data.end_date,
        budget=trip_data.budget,
        interests=trip_data.interests,
        itinerary_json=result.get("itinerary", {}),
        risk_analysis=result.get("risk_analysis", {}),
        quality_score=result["risk_analysis"]["quality_score"]["overall_score"]
    )

    db.add(trip)
    await db.commit()

    return {
        "trip_id": trip.id,
        "itinerary": result.get("itinerary"),
        "risk_analysis": result.get("risk_analysis"),
        "requires_approval": result.get("requires_approval"),
        "warnings": result.get("warnings")
    }
```

**Chat Endpoint:**

```python
@router.post("/chat")
async def chat(chat_request: ChatRequest, user_id: int = 1,
              db: AsyncSession = Depends(get_db)):
    """Simple chat interface (no workflow)"""
    # Get or create conversation
    conversation = await get_or_create_conversation(...)

    # Save user message
    user_message = Message(
        conversation_id=conversation.id,
        role="user",
        content=chat_request.message
    )
    db.add(user_message)

    # Get conversation history
    recent_messages = await get_recent_messages(conversation.id, limit=10)

    # Generate response using Ollama (no RAG, no workflow)
    ollama = OllamaClient()
    messages = [{"role": msg.role, "content": msg.content}
                for msg in recent_messages]
    ai_response = await ollama.chat(messages, temperature=0.7)

    # Save AI response
    ai_message = Message(
        conversation_id=conversation.id,
        role="assistant",
        content=ai_response
    )
    db.add(ai_message)
    await db.commit()

    return {
        "conversation_id": conversation.id,
        "message": ai_response,
        "role": "assistant"
    }
```

**Key Differences:**
- `/api/trips` - Full workflow with all agents, RAG, external APIs
- `/api/chat` - Simple Ollama chat without external data

**Other Endpoints:**

```python
@router.get("/trips/{trip_id}")  # Get trip details
@router.get("/trips")  # List user trips
@router.put("/trips/{trip_id}")  # Update trip
@router.get("/conversations")  # List conversations
@router.get("/memory/{user_id}")  # Get user memory/preferences
@router.post("/users/preferences")  # Update preferences
```

### GraphQL API: `backend/app/api/graphql_schema.py`

```python
@strawberry.type
class Query:
    @strawberry.field
    async def trips(self, user_id: int, info: Info) -> List[Trip]:
        """Get user trips via GraphQL"""
        db = info.context["db"]
        result = await db.execute(
            select(TripModel).where(TripModel.user_id == user_id)
        )
        return result.scalars().all()

    @strawberry.field
    async def trip(self, trip_id: int, info: Info) -> Optional[Trip]:
        """Get single trip"""
        ...

@strawberry.type
class Mutation:
    @strawberry.mutation
    async def create_trip(self, trip_input: TripInput, info: Info) -> Trip:
        """Create trip via GraphQL"""
        ...
```

---

## Part 7: Frontend Architecture (2 minutes)

### Application Structure: `frontend/src/`

**Main App Component:**

```javascript
// App.jsx
function App() {
  return (
    <QueryClientProvider client={queryClient}>
      <Router>
        <div className="min-h-screen bg-gray-50">
          <Navbar />
          <main className="container mx-auto px-4 py-8">
            <Routes>
              <Route path="/" element={<HomePage />} />
              <Route path="/chat" element={<ChatPage />} />
              <Route path="/trips" element={<TripsPage />} />
              <Route path="/trips/:id" element={<TripDetailPage />} />
            </Routes>
          </main>
        </div>
      </Router>
    </QueryClientProvider>
  );
}
```

**API Integration: `frontend/src/services/api.js`**

```javascript
const API_URL = import.meta.env.VITE_API_URL || 'http://localhost:8000';

export const api = {
  // Trip operations
  async createTrip(tripData) {
    const response = await fetch(`${API_URL}/api/trips`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify(tripData)
    });
    return response.json();
  },

  async getTrips(userId = 1) {
    const response = await fetch(`${API_URL}/api/trips?user_id=${userId}`);
    return response.json();
  },

  // Chat operations
  async sendMessage(message, conversationId = null) {
    const response = await fetch(`${API_URL}/api/chat`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        message,
        conversation_id: conversationId,
        user_id: 1
      })
    });
    return response.json();
  }
};
```

**Key Components:**

1. **TripPlanForm** - Form for creating trips (triggers workflow)
2. **ChatMessage** - Chat message display
3. **TripResultCard** - Displays generated itinerary
4. **Navbar** - Navigation between pages
5. **ItineraryTimeline** - Visual itinerary display

---

## Part 8: Data Flow & Integration (2 minutes)

### Complete Data Flow

**Trip Planning Flow:**

```
1. User Input (Frontend)
   â†“
2. POST /api/trips (FastAPI)
   â†“
3. TripPlanningWorkflow.run()
   â†“
4. fetch_data_node
   â”œâ”€ OpenWeatherMap API â†’ weather_data
   â”œâ”€ Eventbrite API â†’ events_data
   â””â”€ ExchangeRate API â†’ exchange_rate
   â†“
5. analyze_risks_node
   â””â”€ RiskAgent â†’ risk_analysis
   â†“
6. retrieve_knowledge_node
   â”œâ”€ FAISS Vector Store â†’ similarity_search
   â””â”€ KnowledgeAgent â†’ knowledge_snippets
   â†“
7. check_major_issues_node
   â””â”€ Evaluate risks â†’ requires_approval?
   â†“
8. generate_itinerary_node
   â”œâ”€ Build comprehensive prompt
   â”œâ”€ Ollama LLM â†’ raw_itinerary
   â””â”€ StrategyAgent â†’ structured_itinerary
   â†“
9. optimize_itinerary_node
   â”œâ”€ Apply weather optimizations
   â””â”€ Apply budget optimizations
   â†“
10. finalize_node
    â””â”€ Generate summary & quality score
    â†“
11. Save to Database (SQLite)
    â†“
12. Return to Frontend
    â””â”€ Display itinerary with visualizations
```

**Chat Flow:**

```
1. User Message (Frontend)
   â†“
2. POST /api/chat (FastAPI)
   â†“
3. Retrieve conversation history (Database)
   â†“
4. Ollama Chat API (No RAG, No Workflow)
   â†“
5. Save message (Database)
   â†“
6. Return to Frontend
   â””â”€ Display in chat interface
```

### External API Integration

**API Configuration: `backend/app/utils/config.py`**

```python
class Settings(BaseSettings):
    # Application
    APP_NAME: str = "AI Travel Advisor"
    DEBUG: bool = True

    # Database
    DATABASE_URL: str = "sqlite+aiosqlite:///./travel_advisor.db"

    # Ollama
    OLLAMA_BASE_URL: str = "http://localhost:11434"
    OLLAMA_MODEL: str = "llama2"

    # Vector Store
    FAISS_INDEX_PATH: str = "./data/faiss_index"
    EMBEDDING_MODEL: str = "sentence-transformers/all-MiniLM-L6-v2"

    # External APIs (optional - uses mock data if not provided)
    OPENWEATHER_API_KEY: Optional[str] = None
    EVENTBRITE_API_KEY: Optional[str] = None
    EXCHANGERATE_API_KEY: Optional[str] = None

    class Config:
        env_file = ".env"
```

**Mock Data Fallback:**

Each agent implements mock data generation when API keys are not available:

```python
# Example from DataAgent
if not self.openweather_api_key:
    logger.warning("Using mock weather data - no API key configured")
    return self._generate_mock_weather(location, start_date, end_date)
```

This ensures the application works without API keys for development and testing.

---

## Part 9: Testing & Documentation (1 minute)

### Test Suite: `backend/tests/`

**Test Files:**
1. `test_agents.py` - Agent functionality (4 tests)
2. `test_api.py` - API endpoints (15+ tests)
3. `test_rag.py` - RAG system (20+ tests)
4. `test_workflow.py` - LangGraph workflow (15+ tests)
5. `test_models.py` - Database models (20 tests)

**Running Tests:**

```bash
cd backend
source venv/bin/activate
PYTHONPATH=. pytest tests/ -v --cov=app
```

**Test Coverage:**
- Services/Agents: 80%+
- RAG System: 75%+
- API Endpoints: 85%+
- Models: 90%+

### Documentation

**Created Documentation:**
1. README.md - Project overview
2. QUICKSTART.md - 5-minute setup guide
3. docs/SETUP_GUIDE.md - Comprehensive setup
4. docs/ARCHITECTURE.md - System architecture
5. docs/API_DOCUMENTATION.md - API reference
6. docs/TESTING.md - Testing guide
7. docs/KNOWN_ISSUES.md - Compatibility issues
8. docs/DATA_SOURCES_EXPLAINED.md - Data integration
9. DOCUMENTATION_INDEX.md - Documentation navigation

---

## Part 10: Key Technical Highlights (1 minute)

### Innovation Points

**1. Multi-Agent Orchestration**
- Four specialized agents working in sequence
- Each agent has a specific responsibility
- State passed between agents via LangGraph

**2. RAG Implementation**
- FAISS for fast vector similarity search
- Sentence Transformers for embeddings
- Curated travel knowledge from multiple sources
- Interest-based re-ranking

**3. Human-in-the-Loop**
- Automatic detection of high-risk scenarios
- User approval checkpoints
- Transparent risk communication

**4. Comprehensive Risk Analysis**
- Budget overrun prediction
- Weather risk scoring
- Crowding analysis
- Quality scoring (0-100)

**5. Flexible Architecture**
- Mock data fallback for APIs
- Simplified workflow fallback for LangGraph
- Works without external dependencies
- Easy to extend with new agents

### Performance Characteristics

- **Response Time**: 10-30 seconds for full trip planning
- **Vector Search**: <100ms for similarity search
- **LLM Generation**: 5-15 seconds depending on itinerary length
- **Database Operations**: <10ms for queries
- **Scalability**: Async operations throughout

### Production Readiness

**Implemented:**
- Error handling and logging
- Data validation (Pydantic schemas)
- Database transactions
- CORS configuration
- Environment-based configuration
- Comprehensive test suite

**Deployment Options:**
- Docker containerization
- Cloud platforms (AWS, GCP, Azure)
- Frontend: Vercel, Netlify
- Backend: Any Python hosting service

---

## Summary

The AI-Driven Personalized Travel Advisor implements a sophisticated multi-agent system with:

- **4 Specialized AI Agents** - Data, Risk, Knowledge, Strategy
- **RAG System** - FAISS + Sentence Transformers + curated knowledge
- **LangGraph Workflow** - Orchestrated multi-step process
- **External API Integration** - Weather, events, currency
- **Human-in-the-Loop** - Risk-based approval checkpoints
- **Full-Stack Application** - FastAPI + React
- **Comprehensive Testing** - 75+ test cases

The codebase demonstrates production-ready architecture with proper separation of concerns, error handling, and extensibility.

---

**Code Walkthrough Document**
**Version**: 1.0
**Date**: 2025-11-19
